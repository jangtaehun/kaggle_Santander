### ğŸ‘¨â€ğŸ« Santander Customer Satisfaction - Machine Learning from Disaster
kaggleì—ì„œ ì œê³µí•˜ëŠ” Santander Customer Satisfactionë¥¼ ì´ìš©í•´ EDAì™€ model í•™ìŠµì„ í†µí•´ ê³ ê° ë§Œì¡±ë„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í”„ë¡œì íŠ¸

---
### â²ï¸ ë¶„ì„ ê¸°ê°„
2024.09.01 - 2024.09.03

---

### ğŸ“ ì†Œê°œ
Santander Customer Satisfaction dataëŠ” ì´ì „ì— ì§„í–‰í–ˆë˜ titanic dataì™€ ë‹¤ë¥´ê²Œ featureì˜ ê°¯ìˆ˜ë„ ë§ìœ¼ë©° ë°ì´í„°ì˜ ì–‘ë„ ë§ë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ featureì˜ ëŒ€ë¶€ë¶„ì´ ê°œì¸ì •ë³´ë¥¼ ì´ìœ ë¡œ featureì˜ ì´ë¦„ì´ ê³µê°œë˜ì§€ ì•Šì€ ë°ì´í„°ì…ë‹ˆë‹¤.

ë”°ë¼ì„œ ì´ë²ˆì—” ë¶„ì„í•  Santander Customer Satisfactionì€ titanic dataì™€ ë‹¤ë¥¸ ì˜ë¯¸ë¡œ ì–´ë ¤ì›€ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

### í”„ë¡œì íŠ¸ ê°œìš”
##### ğŸ“Œ ëª©í‘œ
Kaggleì—ì„œ ê³ ê°ì˜ ì •ë³´ë¥¼ í† ëŒ€ë¡œ Santander ì€í–‰ì´ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ì— ë¶ˆë§Œì¡±ì„ ëŠë¼ëŠ” ê³ ê°ì„ ì‹ë³„í•˜ëŠ” ëŒ€íšŒê°€ 2016ë…„ì— ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. 
ì´ í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” ê³ ê°ì´ Santander ì€í–‰ ì„œë¹„ìŠ¤ì— ë§Œì¡±í•˜ëŠ”ì§€ ë¶ˆë§Œì¡±í•˜ëŠ”ì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ featureì˜ ì´ë¦„ì´ ëª¨ë‘ ìµëª…ì²˜ë¦¬ ë˜ì–´ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¹ì§•ë“¤ì„ ë¶„ì„í•¨ìœ¼ë¡œì¨, ê³ ê° ë§Œì¡±ë„ë¥¼ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ê³ ì í•©ë‹ˆë‹¤.

##### ğŸ–¥ï¸ ë°ì´í„°ì…‹ (Data Set)
ì´ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•œ ë°ì´í„°ì…‹ì€ Kaggleì—ì„œ ì œê³µí•˜ëŠ” ë‹¤ìŒ íŒŒì¼ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
1. train.csv: í›ˆë ¨ ë°ì´í„°ì…‹, íŠ¹ì§•ë“¤ê³¼ ëª©í‘œ ë³€ìˆ˜ë¥¼ í¬í•¨.
2. test.csv: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹, ì˜ˆì¸¡ì„ ìœ„í•´ ì‚¬ìš©ë  ë°ì´í„°.
3. sample_submission.csv: ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œì¶œí•˜ê¸° ìœ„í•œ ìƒ˜í”Œ íŒŒì¼.

---

##### ë°©ë²•ë¡ 
1. ë¬¸ì œì— ëŒ€í•œ ì •ë³´ ìˆ˜ì§‘
  * ë¬¸ì œ ì •ì˜
  * ë¶„ì„ ëŒ€ìƒì— ëŒ€í•œ ì´í•´
2. Santander Customer Satisfaction data setì„ ì´ìš©í•œ EDA
  * ê³µí†µ ì½”ë“œ
    * ì˜¤ì°¨í–‰ë ¬(Confusion matrix) ë° í‰ê°€ ì§€í‘œ
  * ë¶„ì„
    * Santander Customer Satisfaction data setì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì •ë³´
    * feature ë¶„ì„
    * ì´ìƒì¹˜ íƒìƒ‰
    * Data cleaning
    * noise ì²˜ë¦¬
    * Feature Engineering
3. ëª¨ë¸ í•™ìŠµ
  * XGBoost
  * LightGBM
  * CatBoost
  * Ensemble - Voting
4. ê²°ë¡ 
  * í•œê³„ì 

---

### ë¬¸ì œì— ëŒ€í•œ ì •ë³´ ìˆ˜ì§‘
   #### 1. ë¬¸ì œ ì •ì˜
Santander Customer Satisfactionì— ëŒ€í•œ dataëŠ” ê³ ê°ì˜ ë§Œì¡±ë„ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ kaggleì— ë°ì´í„°ë¥¼ ì œê³µí•´ì£¼ì—ˆë‹¤. ë”°ë¼ì„œ Kaggleì—ì„œ ê³ ê°ì˜ ì •ë³´ë¥¼ í† ëŒ€ë¡œ Santander ì€í–‰ì´ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ì— ë¶ˆë§Œì¡±ì„ ëŠë¼ëŠ” ê³ ê°ì„ ì‹ë³„í•˜ëŠ” ëŒ€íšŒê°€ 2016ë…„ì— ì§„í–‰ë˜ì—ˆë‹¤.

train.csvì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ EDAë¥¼ ì§„í–‰í•œ í›„ test.csvì˜ ë°ì´í„°ë¥¼ ì´ìš©í•´ ì˜ˆì¸¡í•œ í›„ ê²°ê³¼ë¥¼sample_submission.csvì™€ ê²°í•©í•œ í›„ ì œì¶œí•˜ê³  ì œì¶œí•˜ë©´ ëœë‹¤.

![image](https://github.com/user-attachments/assets/5026c767-5401-4087-a83c-8baaa8955859)

Santander Customer Satisfaction dataëŠ” ìœ„ì™€ ê°™ì´ ëª¨ë“  featureê°€ ê°œì¸ì •ë³´ë¥¼ ì´ìœ ë¡œ featureì˜ ì´ë¦„ì´ ëª¨ë‘ ìµëª…ì²˜ë¦¬ ë˜ì–´ìˆë‹¤. ë”°ë¼ì„œ ì–´ë–¤ ì†ì„±ì¸ì§€ ì¶”ì •í•  ìˆ˜ ì—†ë‹¤.

TARGETìœ¼ë¡œëŠ” 1ì€ ë¶ˆë§Œì¡±, 0ì€ ë§Œì¡±í•œ ê³ ê°ì„ ë‚˜íƒ€ë‚´ë©°, ê³ ê°ì˜ ë§Œì¡±ë„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œì´ë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ í‰ê°€ì§€í‘œë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³µì§€ë˜ì–´ ìˆë‹¤.

![image](https://github.com/user-attachments/assets/a883b253-d187-4af2-aca2-dcd435bde71e)

<www.kaggle.com/competitions/santander-customer-satisfaction/overview/evaluation>

ROC ê³¡ì„ ì˜ ì•„ë˜ ë©´ì ì„ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€ëœë‹¤. ë”°ë¼ì„œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ AUCë¡œ ì¸¡ì •í•˜ë©°, ë†’ì€ AUCë¥¼ ì–»ëŠ” ê²ƒì´ ëŒ€íšŒì—ì„œ ì¢‹ì€ ì„±ì ì„ ì–»ëŠ” ë° ì¤‘ìš”í•˜ë‹¤.

---

   #### 2. ë¶„ì„ ëŒ€ìƒì— ëŒ€í•œ ì´í•´
Santander ì€í–‰ì€ ìŠ¤í˜ì¸ ì‚°íƒ„ë°ë¥´ì— 1867ë…„ì— ì„¤ë¦½ë˜ ìœ ëŸ½ ìµœëŒ€ ê¸°ì—… ë° ì€í–‰ì´ë‹¤. Santander ì€í–‰ì€ ë‹¤ë¥¸ ì„¸ê³„ì ì¸ ì€í–‰ê³¼ ë‹¤ë¥¸ íŠ¹ì§•ì´ ìˆë‹¤. ëŒ€í˜• ì€í–‰ë“¤ì€ íˆ¬ìê¸ˆìœµ ë¶„ì•¼ ê·œëª¨ê°€ í¬ë‹¤. í•˜ì§€ë§Œ Santander ì€í–‰ì€ ìˆ˜ìµì˜ í° ë¶€ë¶„ì´ ì†Œë§¤ê¸ˆìœµì—ì„œ ë‚˜ì˜¨ë‹¤. ì¦‰, ê¸ˆìœµê¸°ê´€ì¸ Santander ì€í–‰ì´ ê°œì¸ì—ê²Œ ê¸ˆìœµ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ ìˆ˜ìµì˜ í° ë¶€ë¶„ì´ë‹¤.

ì†Œë§¤ê¸ˆìœµì—ì„œ ë‚˜ì˜¤ëŠ” ìˆ˜ìµì´ í¬ê¸° ë•Œë¬¸ì— Santander ì€í–‰ì€ ê³ ê°ì˜ ë§Œì¡±, ë¶ˆë§Œì¡±ì— í° ê´€ì‹¬ì„ ê°€ì§€ê²Œ ëœ ê²ƒìœ¼ë¡œ kaggleì— feature ì´ë¦„ì´ ìµëª…ì²˜ë¦¬ëœ dataë¥¼ ì œê³µí•œ ê²ƒì´ë‹¤.

ê³ ê°ì„ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ë§ì€ ë¶„ì•¼ì—ì„œ ê³ ê° ë§Œì¡±ë„ëŠ” ì„±ê³µì˜ ì¤‘ìš”í•œ ì²™ë„ì´ë‹¤. ê¸°ì—…ì— ë¶ˆë§Œì¡±ì„ ëŠë¼ëŠ” ê³ ê°ì€ ë”ì´ìƒ ê³ ê°ìœ¼ë¡œ ë¨¸ë¬¼ì§€ ì•ŠëŠ”ë‹¤. í•˜ì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ ê³ ê°ì€ ê¸°ì—…ì—ì„œ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ì— ëŒ€í•œ ë¶ˆë§Œì¡±ì„ ë– ë‚˜ê¸° ì „ê¹Œì§€ í˜¹ì€ ë– ë‚œ í›„ì—ë„ ê±°ì˜ í‘œì¶œí•˜ì§€ ì•ŠëŠ”ë‹¤.

ë”°ë¼ì„œ Santander BankëŠ” kaggleì— ê³ ê°ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì œê³µí•˜ë©´ì„œ ì´ˆê¸° ë‹¨ê³„ì—ì„œ ë¶ˆë§Œì¡±í•œ ê³ ê°ì„ ì‹ë³„í•˜ëŠ” ë° ë„ì›€ì„ ìš”ì²­í–ˆë‹¤. ì¦‰, Santander BankëŠ” ê³ ê°ì´ ë– ë‚˜ê¸° ì „ì— ê³ ê°ì˜ ë§Œì¡±ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì„ ì œì ì¸ ì¡°ì¹˜ë¥¼ ì·¨í•˜ê³ ì í•œ ê²ƒì´ë‹¤.

Santander Customer Satisfaction dataëŠ” ì•ì—ì„œ ë§í–ˆë“¯ ìˆ˜ë°± ê°œì˜ ìµëª…í™”ëœ íŠ¹ì§•ì„ ì‚¬ìš©í•˜ì—¬ ê³ ê°ì´ ì€í–‰ ê²½í—˜ì— ë§Œì¡±í•˜ëŠ”ì§€ ë¶ˆë§Œì¡±í•˜ëŠ”ì§€ë¥¼ ì˜ˆì¸¡í•˜ê³ ì í•œë‹¤. í•„ìëŠ” ì´ëŸ¬í•œ íŠ¹ì§•ìœ¼ë¡œ ì¸í•´ Santander Customer Satisfaction ë°ì´í„°ë¥¼ ë§ˆëƒ¥ ì‰¬ìš´ ë‚œì´ë„ë¡œ ë³´ê³ ìˆì§€ ì•Šë‹¤.

---

### Santander Customer Satisfaction data setì„ ì´ìš©í•œ EDA
   #### 1. ê³µí†µ ì½”ë“œ
```
def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred, pos_label=1)
    recall = recall_score(y_test, pred, pos_label=1)
    f1 = f1_score(y_test, pred, pos_label=1)
    roc_auc = roc_auc_score(y_test, pred_proba)

    print('ì˜¤ì°¨ í–‰ë ¬')
    print(confusion)
    print('ì •í™•ë„: {0:.4f}, ì •ë°€ë„: {1:.4f}, ì¬í˜„ìœ¨: {2:.4f}, F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))
```
ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ê³µí†µ ì½”ë“œë¡œ ìœ„ì™€ ê°™ì´ ì˜¤ì°¨í–‰ë ¬, ì •í™•ë„, ì¬í˜„ìœ¨, ì •ë°€ë„, F1 score, ROC ê³¡ì„ ê³¼ AUCë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ì½”ë“œë¥¼ ì‘ì„±í–ˆë‹¤. ê³µí†µ ì½”ë“œëŠ” ëª¨ë¸ì„ ì‚¬ìš©í–ˆì„ ë•Œë§ˆë‹¤ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  ê²ƒìœ¼ë¡œ í•¨ìˆ˜í™” í–ˆë‹¤. ê°ê° ì„¤ëª…ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

1. ì˜¤ì°¨í–‰ë ¬
í˜¼ë™í–‰ë ¬(confusion matrix)ë¼ê³ ë„ ë¶€ë¥¸ë‹¤. í•™ìŠµëœ ë¶„ë¥˜ ëª¨ë¸ì´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ë©´ì„œ ì–¼ë§ˆë‚˜ í˜¼ë™(í˜¼ë€)í•˜ê³  ìˆëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì§€í‘œì´ë‹¤. ë”°ë¼ì„œ ì´ì§„ ë¶„ë¥˜ì—ì„œ ì˜ˆì¸¡ ì˜¤ë¥˜ê°€ ì–¼ë§ˆì¸ì§€, ì–´ë–¤ ìœ í˜•ì˜ ì˜ˆì¸¡ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê³  ìˆëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì§€í‘œì´ë‹¤.
![image](https://github.com/user-attachments/assets/aa79ad40-6ba9-4129-9545-ecb01fe83cb0)

ìœ„ì™€ ê°™ì´ ì´ 4ê°œ ë¶„ë©´ì„ í†µí•´ ë¶„ë¥˜ ëª¨ë¸ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” ì§€í‘œì´ë‹¤. TN, FP, FN, TPê°€ ìˆìœ¼ë©° ê°ê° ë‹¤ìŒê³¼ ê°™ì€ ì§€í‘œë¥¼ ë³´ì—¬ì¤€ë‹¤.

 * TN = ì˜ˆì¸¡ ê°’ì„ Negative ê°’ìœ¼ë¡œ ì˜ˆì¸¡í–ˆê³  ì‹¤ì œ ê°’ì´ Negative
 * FP = ì˜ˆì¸¡ ê°’ì„ Positive ê°’ìœ¼ë¡œ ì˜ˆì¸¡í–ˆê³  ì‹¤ì œ ê°’ì´ Negative
 * FN = ì˜ˆì¸¡ ê°’ì„ Negative ê°’ìœ¼ë¡œ ì˜ˆì¸¡í–ˆê³  ì‹¤ì œ ê°’ì´ Positive
 * TP = ì˜ˆì¸¡ ê°’ì„ Positive ê°’ìœ¼ë¡œ ì˜ˆì¸¡í–ˆê³  ì‹¤ì œ ê°’ì´ Positive
   
 ì´ë ‡ê²Œ 4ê°œ ì •ë³´ë¥¼ í†µí•´ ë¶„ë¥˜ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•  ìˆ˜ ìˆë‹¤. ì˜¤ì°¨í–‰ë ¬ë¥¼ í†µí•´ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ë°©ë²•ìœ¼ë¡œëŠ” ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1 scoreë¥¼ ì•Œ ìˆ˜ ìˆë‹¤.

   ###### ì •í™•ë„ = ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ê°’ì´ ë™ì¼í•œ ê±´ìˆ˜/ì „ì²´ ë°ì´í„° ìˆ˜ (TN + TP) / (TN + FP + FN + TP)
      ì •í™•ë„ëŠ” ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ì¢‹ì€ ì§€í‘œì´ì§€ë§Œ ë¹„ëŒ€ì¹­í•œ ë°ì´í„° ì„¸íŠ¸ì—ì„œëŠ” ìˆ˜ì¹˜ì ì¸ íŒë‹¨ ì˜¤ë¥˜ë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆë‹¤.
   ###### ì •ë°€ë„ = ì˜ˆì¸¡ì„ Positiveë¡œ í•œ ëŒ€ìƒ ì¤‘ì— ì˜ˆì¸¡ê³¼ ì‹¤ì œ ê°’ì´ Positiveë¡œ ì¼ì¹˜í•œ ë°ì´í„°ì˜ ë¹„ìœ¨ TP/ (FP + TP)
      Positive ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë”ìš± ì •ë°€í•˜ê²Œ ì¸¡ì •í•˜ê¸° ìœ„í•œ í‰ê°€ ì§€í‘œë¡œ ì–‘ì„± ì˜ˆì¸¡ë„ë¼ê³  ë¶ˆë¦°ë‹¤.
   ###### ì¬í˜„ìœ¨ = ì‹¤ì œ ê°’ì´ Positiveì¸ ëŒ€ìƒ ì¤‘ì— ì˜ˆì¸¡ê³¼ ì‹¤ì œ ê°’ì´ Positiveë¡œ ì¼ì¹˜í•œ ë°ì´í„°ì˜ ë¹„ìœ¨ TP/ (FN + TP)
      ë¯¼ê°ë„ë¼ê³  ë¶ˆë¦°ë‹¤.

ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ì—ì„œ ì—…ë¬´ íŠ¹ì„±ì— ë”°ë¼ íŠ¹ì • í‰ê°€ ì§€í‘œê°€ ë” ì¤‘ìš”í•œ ì§€í‘œë¡œ ê°„ì£¼ë  ìˆ˜ ìˆë‹¤. ì¬í˜„ìœ¨ì€ ì‹¤ì œ Positive ì–‘ì„± ë°ì´í„°ë¥¼ Negativeë¡œ ì˜ëª» íŒë‹¨í•˜ê²Œ ë˜ë©´ í° ì˜í–¥ì´ ë°œìƒí•˜ëŠ” ì˜ë£Œ ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•˜ë‹¤. ì •ë°€ë„ëŠ” Negative ë°ì´í„°ë¥¼ Positive ë°ì´í„°ë¡œ ì˜ëª» íŒë‹¨í•˜ê²Œ ë˜ë©´ í° ì˜í–¥ì´ ë°œìƒí•˜ëŠ” ìŠ¤íŒ¸ ë©”ì¼ íŒì •ì—ì„œ ì¤‘ìš”í•˜ë‹¤.

   ###### F1 score = ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì„ ê²°í•©í•œ ì§€í‘œ
      F1 ì ìˆ˜ê°€ ë†’ë‹¤ëŠ” ê²ƒì€ ëª¨ë¸ì´ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•˜ë©´ì„œë„ ë§ì€ ê¸ì •ì ì¸ ì‚¬ë¡€ë¥¼ ì¡ì•„ë‚´ê³  ìˆë‹¤ëŠ” ì˜ë¯¸
   ###### ROC ê³¡ì„ ê³¼ AUC = ì´ì§„ ë¶„ë¥˜ì—ì„œ ì˜ˆì¸¡ ì„±ëŠ¥ ì¸¡ì •ì—ì„œ ì¤‘ìš”í•˜ê²Œ ì‚¬ìš©ë˜ëŠ” ì§€í‘œ
      ROC ê³¡ì„ ì€ FPR(False Positive Rate)ì´ ë³€í•  ë•Œ TPR(True Positive Rate)ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê³¡ì„ ì´ë‹¤. FPRì„ Xì¶•ìœ¼ë¡œ, TPRì„ Y ì¶•ìœ¼ë¡œ ì¡ìœ¼ë©´ FPRì˜ ë³€í™”ì— ë”°ë¥¸ TPRì˜ ë³€í™”ê°€ ê³¡ì„  í˜•íƒœë¡œ ë‚˜íƒ€ë‚œë‹¤.
      ë¶„ë¥˜ì˜ ì„±ëŠ¥ ì§€í‘œë¡œ ì‚¬ìš©ë˜ëŠ” ê²ƒì€ ROC ê³¡ì„  ë©´ì ì— ê¸°ë°˜í•œ AUC ê°’ìœ¼ë¡œ ê²°ì •í•œë‹¤.
      AUC(Area Under Curve) ê°’ì€ ROC ê³¡ì„  ë°‘ì˜ ë©´ì ì„ êµ¬í•œ ê²ƒìœ¼ë¡œì„œ ì¼ë°˜ì ìœ¼ë¡œ 1ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ì¢‹ì€ ìˆ˜ì¹˜ì´ë‹¤.
     
ì˜¤ì°¨í–‰ë ¬ê³¼ ì •í™•ë„, ì¬í˜„ìœ¨, ì •ë°€ë„, F1 score, ROC ê³¡ì„ ê³¼ AUCë¥¼ ì„¤ëª…í•œ ì´ìœ ëŠ” ì•ì„œ ì„¤ëª…í–ˆë“¯ Santander Customer Satisfaction ëŒ€íšŒê°€ ROC ê³¡ì„ ì˜ ì•„ë˜ ë©´ì  ì¦‰, AUCë¥¼ í‰ê°€ ì§€í‘œë¡œ í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ ì´ì „ tatinic dataì—ì„œë„ ì‚¬ìš©í–ˆì§€ë§Œ ë”°ë¡œ ì„¤ëª…í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í–ˆë‹¤.

---
   #### 2. ë¶„ì„
   ##### 1. Santander Customer Satisfaction data setì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì •ë³´
Santander Customer Satisfaction dataëŠ” ì•„ë˜ ì‚¬ì§„ê³¼ ê°™ì´ ëª¨ë“  featureê°€ ê°œì¸ì •ë³´ë¥¼ ì´ìœ ë¡œ featureì˜ ì´ë¦„ì´ ëª¨ë‘ ìµëª…ì²˜ë¦¬ ë˜ì–´ìˆë‹¤.
![image](https://github.com/user-attachments/assets/3e4b447e-91b2-487d-931f-4c78b6b60c96)

ë”°ë¼ì„œ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°€ì§„ ê²ƒì¸ì§€ ì¶”ì •í•  ìˆ˜ ì—†ë‹¤. ë”°ë¼ì„œ ìƒê´€ê´€ê³„ì— ëŒ€í•œ ë¶„ì„ì„ ì§„í–‰í•  ê²ƒì´ë©°, ì´ì „ì— ì§„í–‰í–ˆë˜ titanic dataì— ëŒ€í•œ ë¶„ì„ì„ í–ˆë˜ ê²ƒë§Œí¼ ìì„¸í•œ ë¶„ì„ì€ ì§„í–‰í•˜ëŠ” ë° í•œê³„ê°€ ìˆë‹¤.
```
train_df.info()
```
ë°ì´í„°ì— ëŒ€í•œ ì •ë³´ë¥¼ ë³´ë©´ 706,020ê°œì˜ rowê°€ ìˆê³ , 371ê°œì˜ columnì´ ìˆë‹¤. data typeì˜ ê²½ìš° float64, int64 ê°ê° 111ê°œ, 260ê°œë¡œ object typeì€ ì—†ë‹¤. 
```
rain_df.describe()
```
ìš”ì•½ëœ ì •ë³´ë¥¼ ì¢€ ë” ìì„¸í•˜ê²Œ ì•Œ ìˆ˜ ìˆë‹¤. ëª¨ë“  columnsê°€ float, int typeì´ê¸°ì— ìƒëµëœ ë¶€ë¶„ì€ ì—†ì„ ê²ƒì´ë‹¤. í•˜ì§€ë§Œ columnì´ ë§ì•„ ëª¨ë“  í–‰ì´ ì¶œë ¥ë˜ì§€ ì•Šì•„(ì„¤ì •ìœ¼ë¡œ ëª¨ë“  columnì´ ë‚˜ì˜¤ê²Œí•  ìˆ˜ ìˆë‹¤.) ì „ë¶€ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ë‹¤.
![image](https://github.com/user-attachments/assets/7036aefa-8fa5-497a-b333-da723c632431)

ì¶œë ¥ëœ ë‚´ìš©ì„ ë³´ë©´ ì´ìƒí•œ ë¶€ë¶„ì´ var3ì´ë‹¤. var3ì˜ ê²½ìš° min ê°’ì´ -999999ë¡œ ë‚˜ì˜¨ë‹¤. var3ì´ ë¬´ì—‡ì¸ì§€ëŠ” ëª°ë¼ë„ -999999ëŠ” ì¶©ë¶„íˆ ì˜ì‹¬í•  ìˆ˜ ìˆëŠ” ê°’ì´ë‹¤. ì•„ë§ˆ NaNì¸ ê°’ì„ -999999ë¡œ ëŒ€ì²´í–ˆì„ ê°€ëŠ¥ì„±ì´ ìˆë‹¤. ë”°ë¼ì„œ var3ê³¼ ê°™ì´ ì´ìƒì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ì´ ë” ì¡´ì¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— í™•ì¸ì´ í•„ìš”í•˜ë‹¤.

   ##### 2. Feature ë¶„ì„
ë¨¼ì € featureì˜ ìˆ˜ê°€ ë§ìœ¼ë©°, ì •í™•íˆ ì–´ë–¤ ë°ì´í„°ì¸ì§€ í™•ì¸ì´ ë¶ˆë¶„ëª…í•œ ë°ì´í„° ì´ê¸°ì— í•„ìš” ì—†ëŠ” ë°ì´í„°ì™€ í•„ìš”í•œ ë°ì´í„°ë¥¼ êµ¬ë¶„í•´ì•¼ í•œë‹¤. ë”°ë¼ì„œ ëª¨ë“  ê°’ì´ NaNê°’ì¸ ì»¬ëŸ¼ì€ dropí•˜ëŠ” ì‘ì—…ì„ ë¨¼ì € í•˜ê² ë‹¤.
```
all_nan_columns = train_df.columns[train_df.isna().all()].tolist()
print(f"ëª¨ë“  ê°’ì´ NaNì¸ ì»¬ëŸ¼ ê°œìˆ˜: {len(all_nan_columns)}")

train_df.drop(columns=all_nan_columns, inplace=True, axis=1)
test_df.drop(columns=all_nan_columns, inplace=True, axis=1)
```
ìœ„ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥ëœë‹¤. Santanderì—ì„œ ì œê³µí•œ ë°ì´í„°ëŠ” ëª¨ë“  ê°’ì´ NaNê°’ì¸ ì»¬ëŸ¼ì€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.
```
ëª¨ë“  ê°’ì´ NaNì¸ ì»¬ëŸ¼ ê°œìˆ˜: 0
```
NaN ê°’ í™•ì¸ì´ ëë‚¬ìœ¼ë©´ ë‹¤ìŒìœ¼ë¡œ ëª¨ë“  ê°’ì´ ê°™ì€ ì¦‰, íŠ¹ì • ì»¬ëŸ¼ì—ì„œì˜ ê°’ì´ ëª¨ë‘ ê°™ì€ ì»¬ëŸ¼ì„ dropí•˜ëŠ” ì‘ì—…ì„ í•˜ê² ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì–´ë–¤ ì»¬ëŸ¼ì˜ ëª¨ë“  ê°’ì´ 0 ë˜ëŠ” 1ì¸ ì»¬ëŸ¼ì„ dropí•˜ëŠ” ê²ƒì´ë‹¤.
```
unique_one_columns = [col for col in train_df.columns if train_df[col].nunique() == 1]
print(f'ê³ ìœ ê°’ì´ 1ì¸ ì»¬ëŸ¼ ê°œìˆ˜: {len(unique_one_columns)}')
```
ìœ„ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥ëœë‹¤. Santanderì—ì„œ ì œê³µí•œ ë°ì´í„°ëŠ” ê³ ìœ ê°’ì´ 1ì¸ ì»¬ëŸ¼ì´ 34ê°œë‚˜ ì¡´ì¬í•˜ê³  ìˆë‹¤.  ì´ ì»¬ëŸ¼ë“¤ì€ ë‚˜ì¤‘ì— ì œê±°ë¥¼ í•  ê²ƒì´ë‹¤.
```
ê³ ìœ ê°’ì´ 1ì¸ ì»¬ëŸ¼ ê°œìˆ˜: 34
```
ëª¨ë“  ê°’ì´ ê°™ì€ ì»¬ëŸ¼ì„ dropí•˜ëŠ” ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
* ëª¨ë“  ìƒ˜í”Œì—ì„œ ë™ì¼í•œ ê°’ì„ ê°€ì§€ë¯€ë¡œ, ì´ ì»¬ëŸ¼ì€ í•™ìŠµ ë°ì´í„°ì—ì„œ ì–´ë– í•œ ì˜ˆì¸¡ ì •ë³´ë„ ì œê³µí•˜ì§€ ëª» í•˜ê¸° ë•Œë¬¸ì´ë‹¤.
* ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ì„ ì œê±°í•´ ëª¨ë¸ì˜ ë³µì¡ì„±ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤.
* ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ì´ ë§ì„ ê²½ìš°, ëª¨ë¸ì´ ì˜ë¯¸ ì—†ëŠ” íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ê³¼ì í•© ìœ„í—˜ì´ ì¦ê°€í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.
* ë°ì´í„°ì˜ í¬ê¸°ê°€ ì¤„ì–´ë“¤ê¸° ë•Œë¬¸ì— ì €ì¥ ê³µê°„ê³¼ ì²˜ë¦¬ ì‹œê°„ì´ ì ˆì•½ë˜ê¸° ë•Œë¬¸ì— ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ë‹¤ë£° ë•Œ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤.
ìœ„ì™€ ê°™ì€ ì´ìœ ë¡œ ê³ ìœ ê°’ì´ 1ì¸ ì»¬ëŸ¼ ì¦‰, ëª¨ë“  ê°’ì´ ê°™ì€ ì»¬ëŸ¼ì„ dropí•˜ëŠ” ê²ƒì´ë‹¤.
![image](https://github.com/user-attachments/assets/a07a2207-cb60-403c-9aec-24f609277ed2)

ë˜í•œ, ìœ„ì˜ describe() ë©”ì„œë“œë¥¼ í†µí•´ ì–»ì€ ê²°ê³¼ì—ì„œ mean ê°’ì„ ì‚´í´ë³´ë©´ ê°™ì€ ê°’ì„ ê°€ì§„ ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ind_var13_medio_0ì™€ ind_var13_medioë¥¼ ë³´ë©´ mean ê°’ì´ ê°™ë‹¤. ì¦‰, ë‘ ê°œì˜ ì»¬ëŸ¼ì´ ì´ë¦„ë„ ë¹„ìŠ·í•˜ê³  ê°’ë„ ê°™ë‹¤. ë”°ë¼ì„œ ì´ëŸ° ë¶€ë¶„ì— ëŒ€í•´ì„œë„ ì²˜ë¦¬ê°€ í•„ìš”í•˜ë‹¤. ì´ ë¶€ë¶„ ì—­ì‹œ ë‚˜ì¤‘ì— ì œê±°ë¥¼ í•  ê²ƒì´ë‹¤.
   
   ##### 3. ì´ìƒì¹˜ íƒìƒ‰
ì´ìƒì¹˜ ì œê±°ëŠ” ë°ì´í„°ì—ì„œ ë¹„ì •ìƒì ìœ¼ë¡œ í¬ê±°ë‚˜ ì‘ì€ ê°’, ì¦‰ ë‹¤ë¥¸ ë°ì´í„°ì™€ í˜„ì €íˆ ì°¨ì´ê°€ ë‚˜ëŠ” ê°’ì„ ì œê±°í•˜ê±°ë‚˜ ì²˜ë¦¬í•˜ëŠ” ê²ƒìœ¼ë¡œ ë°ì´í„°ì˜ ì™œê³¡ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì‘ì—…ì´ë‹¤. ë”°ë¼ì„œ ì´ìƒì¹˜ë¥¼ íƒìƒ‰í•˜ê³  ì²˜ë¦¬í•˜ê² ë‹¤.

ìœ„ì—ì„œ ì•„ë˜ì™€ ê°™ì´ describe() ë©”ì„œë“œë¥¼ í†µí•´ ìš”ì•½ëœ ì •ë³´ë¥¼ í™•ì¸í–ˆë‹¤. ì´ë•Œ ì£¼ëª©í•  ë¶€ë¶„ì´ var3ìœ¼ë¡œ min ê°’ì´ -999999ë¡œ ë˜ì–´ìˆë‹¤. ë”°ë¼ì„œ Santanderì—ì„œ ì œê³µí•œ ë°ì´í„°ëŠ” ì´ìƒì¹˜ê°€ í¬í•¨ëœ ê°’ìœ¼ë¡œ ì´ìƒì¹˜ë¥¼ íƒìƒ‰í•œ í›„ ì´ìƒì¹˜ì— ëŒ€í•œ ì ì ˆí•œ ì²˜ë¦¬ë¥¼ í•´ì•¼ í•œë‹¤.
![image](https://github.com/user-attachments/assets/a5f5b863-a837-4b55-b67b-1be788f681b4)

ë¨¼ì € var3ì— ëŒ€í•œ ê°’ì„ ì‚´í´ë³´ê² ë‹¤.
```
train_df[train_df['var3']==-999999]
```
ìœ„ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•´ ì•„ë˜ì™€ ê°™ì€ dataframeì„ ì¶œë ¥í•  ìˆ˜ ìˆë‹¤. var3ì˜ ê°’ì´ -999999ì¸ ê°’ì„ ê°€ì§„ rowëŠ” 116ê°œê°€ ìˆë‹¤. ì´ rowëŠ” ë‹¤ë¥¸ ê°’ ì—­ì‹œ ì´ìƒì¹˜ë¥¼ ê°€ì§ˆ í™•ë¥ ì´ ìˆì„ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ë‹¤ë¥¸ ì»¬ëŸ¼ì—ë„ ì´ìƒì¹˜ê°€ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ë° ì¢‹ì€ ì •ë³´ë¥¼ ì¤„ ìˆ˜ ìˆë‹¤.
![image](https://github.com/user-attachments/assets/36b948e0-1ce5-4472-ba28-8155cf4064f0)
![image](https://github.com/user-attachments/assets/4b3430a4-054b-47b8-8b96-a9aca44ef842)

var3ì´ -999999ì¸ ê²ƒë§Œ ë”°ë¡œ ì¶œë ¥í•œ dataframeì„ ë³´ë©´ 0ì´ ìƒë‹¹íˆ ë§ë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ var38ì˜ ê²½ìš° ê°™ì€ ê°’ì„ ê°€ì§„ ìˆ«ìê°€ ë§ë‹¤. ë”°ë¼ì„œ 0ì˜ ê°¯ìˆ˜ì— ë”°ë¥¸ ì²˜ë¦¬ì™€ var38ì— ëŒ€í•œ ì²˜ë¦¬ë„ í•„ìš”í•˜ë‹¤.

###### var3
1. var3ì— ëŒ€í•´ -999999ë¥¼ ê°€ì¥ ë§ì€ ê°’ì„ ê°€ì§€ê³  ìˆëŠ” 2ë¡œ ëŒ€ì²´ (ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´)
ì•„ë˜ì˜ ì½”ë“œë¥¼ í†µí•´ ì–»ì€ ê²°ê³¼ë¥¼ ë³´ë©´ va3 ì»¬ëŸ¼ì—ì„œ ê°€ì¥ ë§ì€ ê°’ì„ ê°€ì§€ê³  ìˆëŠ” ê°’ì€ 2ì´ë‹¤. ë”°ë¼ì„œ 2ë¡œ -999999ë¥¼ ëŒ€ì²´í•˜ëŠ” ë°©ë²•ì„ ì ìš©í•´ ë³¼ ê²ƒì´ë‹¤.
```
train_df['var3'].value_counts()
```
![image](https://github.com/user-attachments/assets/6279b6a6-0833-4895-b471-0db92d7ae21c)

2. va3ì— ëŒ€í•´ -999999ë¥¼ NaN ê°’ì— ëŒ€í•œ ì²˜ë¦¬ë¡œ ì˜ˆìƒí•˜ê³  ìˆê¸° ë•Œë¬¸ì— ê°’ì„ -1ë¡œ ëŒ€ì²´ (ê³ ì •ê°’ ëŒ€ì²´)
3. var3ì˜ -999999ë¥¼ ìƒˆë¡œìš´ ì—´ë¡œ ë§Œë“¤ì–´ ì¶”ê°€ (NaN ê°’ ìì²´ë¥¼ íŠ¹ì„±í™”)

###### var38
í•„ìëŠ” var38ì—ì„œ 117310.979016494ì˜ ê°’ì´ var38ì—ì„œ NaN ê°’ì„ í‰ê· ìœ¼ë¡œ ëŒ€ì²´í•œ ê°’ì´ë¼ ìƒê°í•œë‹¤. ê·¸ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. í•„ìëŠ” ë§ˆì§€ë§‰ì— ìˆëŠ” vr38ì´ ê³ ê°ì˜ ìì‚°ì´ì§€ ì•Šì„ê¹Œ ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ ì˜ˆì¸¡í•˜ê³  ìˆë‹¤. ì´ë•Œ ì•„ë˜ì˜ ì½”ë“œë¥¼ í†µí•´ ì–»ì€ ê²°ê³¼ë¥¼ ë³´ë©´ ìì‚°ì´ ê°™ì€ ê°’ì´ 14868ê°œë¼ ë³´ê¸°ì—” ì´ìƒí•˜ë‹¤. var3ì— ëŒ€í•´ì„œëŠ” -999999ê°€ ì´ìƒì¹˜ë¼ êµ¬ë¶„ì´ ê°”ì§€ë§Œ var38ì— ëŒ€í•´ì„œëŠ” 57736ê°œì˜ nuniqueê°€ ìˆëŠ”ë° ìœ ë… í•˜ë‚˜ì˜ ê°’ì— ëª°ë ¤ ìˆë‹¤ëŠ” ê²ƒì€ ì´ìƒí•˜ë‹¤ ë³´ê¸° ë•Œë¬¸ì´ë‹¤. ë”°ë¼ì„œ ì´ ë¶€ë¶„ì— ëŒ€í•´ì„œë„ ì²˜ë¦¬ë¥¼ í•´ë³´ë ¤ê³  í•œë‹¤.
```
train_df['var38'].value_counts()
```
![image](https://github.com/user-attachments/assets/7cf52567-c5fd-4034-b3c6-46248a9d36ec)
1. va38ì— ëŒ€í•´ 117310.979016494ë¥¼ NaN ê°’ì— ëŒ€í•œ ì²˜ë¦¬ë¡œ ì˜ˆìƒí•˜ê³  ìˆê¸° ë•Œë¬¸ì— ê°’ì„ -1ë¡œ ëŒ€ì²´ (ê³ ì •ê°’ ëŒ€ì²´)
2. var38ì˜ 117310.979016494ë¥¼ ìƒˆë¡œìš´ ì—´ë¡œ ë§Œë“¤ì–´ ì¶”ê°€ (NaN ê°’ ìì²´ë¥¼ íŠ¹ì„±í™”)
3. var38ì˜ 117310.979016494ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
ì´ë ‡ê²Œ ì´ 6ê°€ì§€ì˜ ë°©ë²•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ë ¤ê³  í•œë‹¤.

##### 4. Data cleaning
ë…¸ì´ì¦ˆ ì œê±°ëŠ” ë°ì´í„°ì—ì„œ ë¶ˆí•„ìš”í•˜ê±°ë‚˜ ë¬´ì‘ìœ„ì ì¸ ë³€ë™ì„ ì œê±°í•˜ì—¬ ë°ì´í„°ì˜ ì‹ í˜¸ë¥¼ ëª…í™•í•˜ê²Œ í•˜ê³ , ë¶„ì„ ë˜ëŠ” ëª¨ë¸ë§ì˜ ì •í™•ì„±ì„ ë†’ì´ëŠ” ê²ƒìœ¼ë¡œ ë°ì´í„°ì˜ ë³¸ì§ˆì ì¸ ì‹ í˜¸ë¥¼ ë” ì˜ ì´í•´í•˜ê±°ë‚˜ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì‘ì—…ì´ë‹¤. ë”°ë¼ì„œ ë…¸ì´ì¦ˆë¥¼ íƒìƒ‰í•˜ê³  ì²˜ë¦¬í•˜ê² ë‹¤.

ë‹¤ìŒìœ¼ë¡œ ê°™ì€ ê°™ì€ í”¼ì²˜(íŠ¹ì§•)ë¥¼ ê°€ì§„ í–‰ì´ ì„œë¡œ ë‹¤ë¥¸ í´ë˜ìŠ¤ ë ˆì´ë¸”(TARGET)ì„ ê°€ì§€ëŠ” ê²½ìš°ë¥¼ ì°¾ì•„ì„œ ì²˜ë¦¬í•˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•˜ë ¤ í•œë‹¤. ë¨¼ì € ID, TARGET ì»¬ëŸ¼ì„ ì œê±° ë° ë¶„ë¦¬í•˜ëŠ” ì‘ì—…ì„ í•˜ê² ë‹¤.
```
train_df.drop(['ID'], axis=1, inplace=True)
test_df.drop(['ID'], axis=1, inplace=True)

y = train_df['TARGET']
X = train_df.drop('TARGET', axis=1)
```
IDì™€ TARGETì„ ì œê±°í•œ ë‹¤ìŒ ìœ„ì—ì„œ í™•ì¸í–ˆë˜ ê³ ìœ ê°’ì´ 1ì¸ ì»¬ëŸ¼ì„ ì œê±°í•  ê²ƒì´ë‹¤. ì•„ë˜ì˜ ì½”ë“œë¥¼ ì´ìš©í•´ ì œê±°ë¥¼ í•˜ë©´ ì´ 34ì˜ ì»¬ëŸ¼ì„ ì œê±°í•´ ë‚¨ì€ ì»¬ëŸ¼ì€ 337ê°œì˜ ì»¬ëŸ¼ë§Œ ë‚¨ëŠ”ë‹¤.
```
unique_one_columns = [col for col in train_df.columns if train_df[col].nunique() == 1]
print(f'ê³ ìœ ê°’ì´ 1ì¸ ì»¬ëŸ¼ ê°œìˆ˜: {len(unique_one_columns)}')

train_df.drop(columns=unique_one_columns, inplace=True, axis=1)
test_df.drop(columns=unique_one_columns, inplace=True, axis=1)
```
ì´ë²ˆì—ë„ ìœ„ì—ì„œ í™•ì¸í–ˆë“¯ ê°™ì€ ê°’ì„ ê°€ì§„ ì»¬ëŸ¼ì„ ì œê±°í•  ê²ƒì´ë‹¤. ì•„ë˜ì™€ ê°™ì€ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. 
```
duplicate_columns = []
columns = train_df.columns

for i in range(len(columns)):
    for j in range(i + 1, len(columns)):
        if train_df[columns[i]].equals(train_df[columns[j]]):
            duplicate_columns.append((columns[i], columns[j]))

for col1, col2 in duplicate_columns:
    print(f"{col1} == {col2}")
    train_df.drop([col2], axis=1, inplace=True)
    test_df.drop([col2], axis=1, inplace=True)
```
![image](https://github.com/user-attachments/assets/7960ab5d-3dff-4456-a01e-fc4bb7604fe5)

ìœ„ì— ìˆëŠ” ì¶œë ¥ ê°’ë“¤ì´ ëª¨ë‘ ì„œë¡œ ê°™ì€ ê°’ì„ ê°€ì§„ ì»¬ëŸ¼ì´ë‹¤. var6_0, var29_0, var6, var29ê°€ ì„œë¡œ ê°™ì€ ê°’ì„ ê°€ì§„ë‹¤ëŠ” ê²ƒì„ ì œì™¸í•˜ë©´ ëª¨ë“  ì»¬ëŸ¼ì´ ë¹„ìŠ·í•œ ì´ë¦„ì„ ê°€ì§„ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ ì»¬ëŸ¼ë“¤ì„ ì œê±°í•˜ë©´ 29ê°œì˜ ì»¬ëŸ¼ì´ ì¶”ê°€ì ìœ¼ë¡œ ì‚­ì œë˜ì–´ 308ê°œì˜ columnì´ ë‚¨ëŠ”ë‹¤.
```
train_with_target = pd.concat([X, y], axis=1)
duplicates = train_with_target.duplicated(keep=False)
duplicates_with_different_target = duplicates & (train_with_target.groupby(list(X.columns))['TARGET'].transform('nunique') > 1)

noise = train_with_target[duplicates_with_different_target]
cleaned_train = train_with_target[~duplicates_with_different_target]

X = cleaned_train.drop('TARGET', axis=1)
y = cleaned_train['TARGET']
```
ì´ë²ˆì—ëŠ” columnì´ ì•„ë‹Œ rowì—ì„œ data cleaningì„ í•˜ë ¤ê³  í•œë‹¤. noise ì¦‰, ì¤‘ë³µëœ í”¼ì²˜ ê°’ì„ ê°€ì§„ ë°ì´í„° ì¤‘ì—ì„œ íƒ€ê²Ÿ ê°’ì´ ë‹¤ë¥¸ ë°ì´í„°ë¥¼ í™•ì¸í•˜ê³  ì œê±°í•˜ê³ ì í•œë‹¤. ìœ„ì˜ ì½”ë“œë¥¼ ì¶œë ¥í•´ë³´ë©´ ì•„ë˜ì™€ ê°™ë‹¤. ì´ 2435ê°œì˜ í–‰ì´ ì¤‘ë³µëœ ê²ƒì´ë‹¤.
![image](https://github.com/user-attachments/assets/a89de785-8121-4456-a369-ba1529fbfc18)

ê²°ê³¼ì ìœ¼ë¡œ Xì—ì„œ ì œê±°ëœ í–‰ì˜ ê°œìˆ˜ëŠ” 2435ì˜ í–‰ì´ ì œê±° ë˜ì–´ ì´ 73290ê°œì˜ í–‰ì´ ë‚¨ëŠ”ë‹¤. ë”°ë¼ì„œ ë™ì¼í•œ í–‰ì„ ê°€ì§€ì§€ë§Œ ë‹¤ë¥¸ íƒ€ê²Ÿ ê°’ì„ ê°€ì§€ëŠ” í–‰ì´ ë§¤ìš° ë§ì•˜ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ìœ„ì—ì„œ ì–¸ê¸‰í–ˆë“¯ 0ê³¼ var3ì˜ -999999 ê°’ì„ ìµœë¹ˆê°’ì¸ 2ë¡œ ëŒ€ì²´í•œ í›„ var38ì˜ 117310.979016494ë¥¼ -1ë¡œ ëŒ€ì²´í•˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•˜ê² ë‹¤.
```
X['var3'].replace(-999999, 2, inplace=True)
test_df['var3'].replace(-999999, 2, inplace=True)

X.loc[np.isclose(X['var38'], 117310.979016), 'var38'] = -1
test_df.loc[np.isclose(test_df['var38'], 117310.979016), 'var38'] = -1
```
ìœ„ì˜ ì½”ë“œë¥¼ í†µí•´ var3ê³¼ var38ì— ëŒ€í•´ ì²˜ë¦¬ë¥¼ í–ˆë‹¤.

ë‹¤ìŒìœ¼ë¡œ isolationforestë¥¼ ì‚¬ìš©í•´ ì´ìƒì¹˜ íƒì§€ë¥¼ í•˜ê² ë‹¤. isolationforestëŠ”ë¹„ì§€ë„í•™ìŠµ ê¸°ë°˜ì˜ ì´ìƒ íƒì§€ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. ë¹„ì§€ë„ í•™ìŠµ ì¤‘ì—ì„œ ì´ìƒì¹˜ë¥¼ íƒì§€í•˜ëŠ” ë° ê°•ë ¥í•œ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. Santander Customer Satisfaction dataëŠ” ì´ìƒì¹˜ë¥¼ íƒì§€í•˜ê¸° ì–´ë ¤ìš´ ë°ì´í„°ë¼ ëª¨ë¸ì„ í†µí•´ ì´ìƒì¹˜ë¥¼ ì œê±°í–ˆë‹¤.
```
from sklearn.ensemble import IsolationForest
import plotly.express as px 

# ë¹„ì§€ë„í•™ìŠµ ê¸°ë°˜ì˜ ì´ìƒ íƒì§€ ì•Œê³ ë¦¬ì¦˜
clf = IsolationForest(
    n_estimators=50, 
    max_samples=50, 
    contamination=float(0.004), 
    max_features=1.0, 
    bootstrap=False, 
    n_jobs=-1, 
    verbose=0)

# ëª¨ë¸ í•™ìŠµ
clf.fit(X)
pred = clf.predict(X)

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
X['label'] = pred

# ì´ìƒì¹˜ ë°ì´í„° ì¶”ì¶œ / 1=ì •ìƒ, -1=ì´ìƒì¹˜
outliers = X.loc[X['label'] == -1]
outlier_index = list(outliers.index)

# ì´ìƒì¹˜ì™€ ì •ìƒì¹˜ ê°œìˆ˜ ì¶œë ¥
print(X['label'].value_counts()) 

# ì´ìƒì¹˜ë¥¼ ì œì™¸í•œ ë°ì´í„° ì¶”ì¶œ
X = X.loc[X['label'] != -1]
X = X.drop(columns=['label'])  # 'label' ì—´ ì œê±°

# yì—ì„œë„ ì´ìƒì¹˜ ì¸ë±ìŠ¤ ì œê±°
y = y.drop(outlier_index)
```

   ##### 5. noise ì²˜ë¦¬
ë‹¤ìŒìœ¼ë¡œ ë™ì¼í•œ í–‰ì„ ê°€ì§€ì§€ë§Œ ë‹¤ë¥¸ íƒ€ê²Ÿ ê°’ì„ ê°€ì§€ëŠ” í–‰ì´ ìˆê¸° ë•Œë¬¸ì— ë°ì´í„°ë¥¼ 5ê°œë¡œ ë‚˜ëˆˆ í›„ ëª¨ë¸ì„ í•™ìŠµí•´ ë…¸ì´ì¦ˆ ë°ì´í„°ì— ëŒ€í•´ TARGET ê°’ì„ ì˜ˆì¸¡í•˜ê² ë‹¤. ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì–´ ì—¬ëŸ¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì€ ëª¨ë¸ì˜ ì•ˆì •ì„±ê³¼ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì´ê³ , ë°ì´í„°ì˜ ë‹¤ì–‘ì„±ì„ ì¶©ë¶„íˆ ë°˜ì˜í•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.
ì•„ë˜ëŠ” LGBMClassifierë¥¼ í†µí•´ noiseì— ëŒ€í•œ TARGET ê°’ì„ ì˜ˆì¸¡í•œ ê²ƒì´ë‹¤.
```
import optuna
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score
from scipy.sparse import csr_matrix

train_parts = np.array_split(X, 5)
train_y_parts = np.array_split(y, 5)

def objective(trial):
    param = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'boosting_type': 'gbdt',
        'num_leaves': trial.suggest_int('num_leaves', 20, 60),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
        'min_child_weight': trial.suggest_float('min_child_weight', 0.1, 10.0),
        'max_depth': trial.suggest_int('max_depth', 2, 10),
        'subsample': trial.suggest_float('subsample', 0.5, 0.8),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.8),
        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True),
        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 50.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 1.0, 20.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 20.0),
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000)
    }

    f1_scores = []
    
    for train_part, train_y_part in zip(train_parts, train_y_parts):
        lgb_model = LGBMClassifier(**param, random_state=42)
        lgb_model.fit(train_part, train_y_part)
        
        y_val_pred = lgb_model.predict(train_part)
        f1 = f1_score(train_y_part, y_val_pred)
        f1_scores.append(f1)
    
    return np.mean(f1_scores)

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

best_params = study.best_params


best_lgb_model = LGBMClassifier(**best_params, random_state=42)
bst_models = []

for train_part, train_y_part in zip(train_parts, train_y_parts):
    best_lgb_model.fit(train_part, train_y_part)
    bst_models.append(best_lgb_model)

noise['TARGET'] = 0
noise_preds = np.mean([model.predict(noise.drop('TARGET', axis=1)) for model in bst_models], axis=0)

noise['TARGET'] = (noise_preds >= 0.5).astype(int)

X = pd.concat([X, noise.drop('TARGET', axis=1)])
y = pd.concat([y, noise['TARGET']])
```
noise ë°ì´í„°ì— ëŒ€í•´ 5ê°œì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ íƒ€ê²Ÿ ê°’ì„ ì˜ˆì¸¡í•œ í›„ ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’ì„ í‰ê·  ë‚´ì–´ noise_predsì— ì €ì¥í•˜ê³ , ê·¸ ê°’ì´ 0.5 ì´ìƒì´ë©´ 1, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0ìœ¼ë¡œ íƒ€ê²Ÿ ê°’ì„ ì„¤ì •í•œ ê²ƒì´ë‹¤.

ìœ„ì˜ ì½”ë“œì™€ ê°™ì´ ì§„í–‰í•˜ë©´ noiseë¡œ ë¶„ë¥˜ë˜ì–´ ì‚­ì œë˜ì—ˆë˜ ë¶€ë¶„ì˜ TARGETì„ ìƒˆë¡­ê²Œ ì˜ˆì¸¡í•´ isolationforestë¡œ ì œê±°í•œ ì´ìƒì¹˜ í–‰ì„ ì œì™¸í•œ 75725ê°œì˜ í–‰ë§Œ ë‚¨ëŠ”ë‹¤. 

   ##### 6. Feature Engineering
ë§ˆì§€ë§‰ìœ¼ë¡œ 0ì— ëŒ€í•œ ì²˜ë¦¬ë¥¼ ì§„í–‰í•˜ê² ë‹¤. ì§€ê¸ˆê¹Œì§€ í™•ì¸í–ˆë“¯ì´ Santanderì—ì„œ ì œê³µí•œ Santander Customer Satisfaction ë°ì´í„°ëŠ” 0ì´ êµ‰ì¥íˆ ë§ë‹¤. ë”°ë¼ì„œ ì´ ë¶€ë¶„ì— ëŒ€í•´ì„œë„ ì ì ˆí•œ ì²˜ë¦¬ê°€  í•„ìš”í•˜ë‹¤. í•„ìëŠ” ê° í–‰(row)ì—ì„œ 0ì˜ ê°¯ìˆ˜ë¥¼ ìƒˆë¡œìš´ ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥í•  ê²ƒì´ë‹¤. ì•„ë˜ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ê²°ê³¼ê°€ ë‚˜ì˜¨ë‹¤.
```
train_df['count_0'] = (train_df == 0).sum(axis=1)
test_df['count_0'] = (test_df == 0).sum(axis=1)
```
![image](https://github.com/user-attachments/assets/6273c3a8-eead-400c-9299-342ba2683a94)

ì¶”ê°€ì ìœ¼ë¡œ var15ì— ëŒ€í•´ì„œë„ ì¶”ê°€ì ì¸ ë¶„ì„ì„ ì§„í–‰í•˜ë˜ ì¤‘ íŠ¹ì • íŒ¨í„´ì„ ë°œê²¬í–ˆë‹¤. ì•„ë˜ì˜ ì½”ë“œë¥¼ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```
var15_values_when_target_1 = train_df[train_df['TARGET'] == 1]['var15']

unique_var15_values = np.sort(var15_values_when_target_1.unique())
unique_var15_values
```
ìœ„ì™€ ê°™ì´ ì½”ë“œë¥¼ ì…ë ¥í•˜ê³  ì‹¤í–‰í–ˆì„ ë•Œ ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥ì´ ëœë‹¤. var15ëŠ” 5ë¶€í„° ê°’ì´ ìˆëŠ” ê²ƒìœ¼ë¡œ 23ë³´ë‹¤ ì‘ìœ¼ë©´ ëª¨ë“  ê°’ì´ 0ì´ë¼ëŠ” ê²ƒì´ë‹¤. ë”°ë¼ì„œ var15ê°€ 23ë³´ë‹¤ ì‘ìœ¼ë©´ 0ìœ¼ë¡œ í•˜ë“œì½”ë”©ì„ í•  ìˆ˜ ìˆë‹¤.
![image](https://github.com/user-attachments/assets/9f0b90c9-88b0-4921-a636-8cb77192a3fb)

---

### ëª¨ë¸ í•™ìŠµ
RandomUnderSampler() í´ë˜ìŠ¤ë¥¼ ì´ìš©í•´ ë°ì´í„°ì˜ ë¶ˆê· í˜•ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ì½”ë“œì´ë‹¤. Santander Customer Satisfaction dataëŠ” ë¶ˆê· í˜•í•œ ë°ì´í„°ì´ë‹¤. ë”°ë¼ì„œ ì´ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë°©ë²•ì´ í•„ìš”í•˜ë‹¤. í•„ìëŠ” ì˜¤ë²„ìƒ˜í”Œë§, ì–¸ë”ìƒ˜í”Œë§, í•˜ì´ë¸Œë¦¬ë“œ ìƒ˜í”Œë§ì—ì„œ ì–¸ë”ìƒ˜í”Œë§ì„ ì„ íƒí–ˆë‹¤. ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ì–¸ë” ìƒ˜í”Œë§ì€ ë°ì´í„°ì—ì„œ ë¹ˆë„ê°€ ë†’ì€ í´ë˜ìŠ¤ì˜ í‘œë³¸ ìˆ˜ë¥¼ ê°ì†Œì‹œì¼œ ë¹ˆë„ê°€ ì ì€ í´ë˜ìŠ¤ì™€ ë¹„ìŠ·í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë§ì¶”ëŠ” ë°©ë²•ì´ë‹¤. ë‹¤ìˆ˜ í´ë˜ìŠ¤ì˜ í‘œë³¸ ìˆ˜ë¥¼ ì¤„ì´ë©´ ëª¨ë¸ì´ ì†Œìˆ˜ í´ë˜ìŠ¤ë„ ì˜ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤€ë‹¤. ë˜í•œ, ê³¼ë‹¤í‘œí˜„ëœ í´ë˜ìŠ¤ì˜ ë°ì´í„°ë¥¼ ì¤„ì—¬ ì†Œìˆ˜ í´ë˜ìŠ¤ì— ëŒ€í•œ ì¬í˜„ìœ¨ì„ ë†’ì´ê³  ëª¨ë¸ì˜ í¸í–¥ì„ ë°©ì§€í•˜ëŠ” ë° íš¨ê³¼ì ì´ê¸° ë•Œë¬¸ì— ì‚¬ìš©í–ˆë‹¤. í•˜ì§€ë§Œ ë°ì´í„° ì†ì‹¤ì˜ ìœ„í—˜ì´ ìˆê¸° ë•Œë¬¸ì— ì¡°ì‹¬í•´ì•¼ í•œë‹¤.

ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ê¸° ì „ì— ë°ì´í„°ì— ëŒ€í•œ ì²˜ë¦¬ë¥¼ ë¨¼ì €í•  ê²ƒì´ë‹¤. StandardScaler()ë¥¼ í†µí•´ íŠ¹ì„±(Feature)ì˜ ê°’ ë²”ìœ„ë¥¼ í‘œì¤€í™”í•˜ê±°ë‚˜ ì •ê·œí™”í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹˜ê³  ë°ì´í„°ë¥¼ ì–¸ë” ìƒ˜í”Œë§ì„ í•œ í›„ train ì„¸íŠ¸ì™€ test ì„¸íŠ¸ë¡œ ë‚˜ëˆŒ ê²ƒì´ë‹¤. ì´í›„ ì–¸ë”ìƒ˜í”Œë§ì„ ì§„í–‰í•˜ê³  train, test ì„¸íŠ¸ë¡œ ë‚˜ëˆŒ ê²ƒì´ë‹¤.
```
sc = StandardScaler()
X = sc.fit_transform(X)
test_df = sc.transform(test_df)
```
```
from imblearn.under_sampling import RandomUnderSampler
from sklearn.model_selection import train_test_split, KFold

X_resampled, y_resampled = RandomUnderSampler(random_state=42, sampling_strategy=0.3).fit_resample(X, y)
X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)
```

   #### XGBoost
ë¨¼ì € XGBoostë¥¼ ì‚¬ìš©í•  ê²ƒì´ë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìœ„í•´ optunaë¥¼ ì‚¬ìš©í–ˆë‹¤.
```
import optuna
from xgboost import XGBClassifier
from sklearn.metrics import f1_score, classification_report, accuracy_score, precision_score, recall_score

def objective(trial):
    param = {
        'objective': 'binary:logistic',
        'eval_metric': 'logloss',
        'booster': 'gbtree',
        'num_leaves': trial.suggest_int('num_leaves', 20, 60),  # XGBoostì—ì„œëŠ” num_leaves ëŒ€ì‹  max_leavesê°€ ìˆìŒ. ê·¸ëŸ¬ë‚˜ ìƒëµ ê°€ëŠ¥.
        'min_child_weight': trial.suggest_float('min_child_weight', 0.1, 10.0),
        'max_depth': trial.suggest_int('max_depth', 2, 10),
        'subsample': trial.suggest_float('subsample', 0.5, 0.8),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.8),
        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True),
        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 50.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 1.0, 20.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 20.0),
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000)
    }

    xgb_model = XGBClassifier(**param, random_state=42, use_label_encoder=False)
    xgb_model.fit(X_train, y_train)
    
    y_val_pred = xgb_model.predict(X_val)
    
    f1 = f1_score(y_val, y_val_pred, pos_label=1) 
    return f1

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

best_params = study.best_params
print("Best params: ", best_params)

best_xgb_model = XGBClassifier(**best_params, random_state=42, use_label_encoder=False)
best_xgb_model.fit(X_train, y_train)

y_val_pred = best_xgb_model.predict(X_val)

print(classification_report(y_val, y_val_pred))
print(f"Accuracy: {accuracy_score(y_val, y_val_pred)}")
print(f"F1 Score: {f1_score(y_val, y_val_pred, pos_label=1)}")
print(f"Precision: {precision_score(y_val, y_val_pred, pos_label=1)}")  
print(f"Recall: {recall_score(y_val, y_val_pred, pos_label=1)}")
```

```
y_train_pred = best_xgb_model.predict(X_train)
y_train_pred_proba = best_xgb_model.predict_proba(X_train)[:, 1]

y_test_pred = best_xgb_model.predict(X_val)
y_test_pred_proba = best_xgb_model.predict_proba(X_val)[:, 1]

print("Train Data Evaluation:")
get_clf_eval(y_train, y_train_pred, y_train_pred_proba)
print("\nValidation Data Evaluation:")
get_clf_eval(y_val, y_test_pred, y_test_pred_proba)
```
ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```
Train Data Evaluation:
ì˜¤ì°¨ í–‰ë ¬
[[7461 1626]
 [ 314 2461]]
ì •í™•ë„: 0.8365, ì •ë°€ë„: 0.6022, ì¬í˜„ìœ¨: 0.8868,    F1: 0.7173, AUC:0.9236

Validation Data Evaluation:
ì˜¤ì°¨ í–‰ë ¬
[[1848  471]
 [ 122  525]]
ì •í™•ë„: 0.8001, ì •ë°€ë„: 0.5271, ì¬í˜„ìœ¨: 0.8114,    F1: 0.6391, AUC:0.8751
```
ë‹¤ìŒìœ¼ë¡œ var15ì— ëŒ€í•´ 23ë³´ë‹¤ ì‘ìœ¼ë©´ 0ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—…ì„ í•˜ê² ë‹¤.
```
test_df = pd.DataFrame(test_df, columns=columns)

predict_santander_pred_xgb = best_xgb_model.predict(test_df)
test_df['TARGET'] = predict_santander_pred_xgb

test_y = test_df['TARGET']
test_X = test_df.drop(['TARGET'], axis=1)

test_df_original = sc.inverse_transform(test_X)
test_df_original = pd.DataFrame(test_df_original, columns=columns)

test_df_original['TARGET'] = test_y.values
test_df_original.loc[test_df_original['var15'] < 23, 'TARGET'] = 0

santander_submission_df['TARGET'] = test_df['TARGET']

# ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
santander_submission_df.to_csv('santander_submission_lgbm.csv', index=False)
santander_submission_df
```
best íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ í†µí•´ ìœ„ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ê²°ê³¼ê°€ ë‚˜ì˜¨ë‹¤.
![image](https://github.com/user-attachments/assets/fcf15518-f940-4182-8e85-a94edbe390ca)

ì¢‹ì€ ì ìˆ˜ë¥¼ ë³´ì—¬ì¤€ë‹¤.


   #### LightGBM
```
import optuna

def objective(trial):
    param = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'boosting_type': 'gbdt',
        'num_leaves': trial.suggest_int('num_leaves', 20, 60),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
        'min_child_weight': trial.suggest_float('min_child_weight', 0.1, 10.0),
        'max_depth': trial.suggest_int('max_depth', 2, 10),
        'subsample': trial.suggest_float('subsample', 0.5, 0.8),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.8),
        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True),
        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 50.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 1.0, 20.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 20.0),
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000)
    }

    lgb_model = LGBMClassifier(**param, random_state=42, verbose=-1)
    lgb_model.fit(X_train, y_train)
    y_val_pred = lgb_model.predict(X_val)
    f1 = f1_score(y_val, y_val_pred, pos_label=1) 
    return f1

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=200)

best_params = study.best_params
print("Best params: ", best_params)

best_lgb_model = LGBMClassifier(**best_params, random_state=42)
best_lgb_model.fit(X_train, y_train)

y_val_pred = best_lgb_model.predict(X_val)

y_train_pred = best_lgb_model.predict(X_train)
y_train_pred_proba = best_lgb_model.predict_proba(X_train)[:, 1]

y_test_pred = best_lgb_model.predict(X_val)
y_test_pred_proba = best_lgb_model.predict_proba(X_val)[:, 1]

get_clf_eval(y_train, y_train_pred, y_train_pred_proba)
get_clf_eval(y_val, y_test_pred, y_test_pred_proba)
```
ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì´ ë‚˜ì˜¨ë‹¤. XGBoostê°€ ì¬í˜„ìœ¨(Recall)ê³¼ F1 ì ìˆ˜ì—ì„œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê¸° ë•Œë¬¸ì—, íŠ¹íˆ ì¬í˜„ìœ¨ì´ ì¤‘ìš”í•œ ë¬¸ì œ(ì˜ˆ: ì§ˆë³‘ ì§„ë‹¨, ì‚¬ê¸° íƒì§€ ë“±)ì—ì„œëŠ” XGBoostê°€ ë” ì í•©í•  ìˆ˜ ìˆë‹¤.
```
Train Data Evaluation:
ì˜¤ì°¨ í–‰ë ¬
[[7468 1219]
 [ 674 1999]]
ì •í™•ë„: 0.8334, ì •ë°€ë„: 0.6212, ì¬í˜„ìœ¨: 0.7478,    F1: 0.6787, AUC:0.8911

Validation Data Evaluation:
ì˜¤ì°¨ í–‰ë ¬
[[1901  335]
 [ 176  428]]
ì •í™•ë„: 0.8201, ì •ë°€ë„: 0.5609, ì¬í˜„ìœ¨: 0.7086,    F1: 0.6262, AUC:0.8672
```
ë‹¤ìŒìœ¼ë¡œ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’ì—ì„œ var15ì˜ ê°’ì´ 23ë³´ë‹¤ ì‘ì„ ê²½ìš° 0ìœ¼ë¡œ ë°”ê¾¸ëŠ” ì‘ì—…ì„ í•  ê²ƒì´ë‹¤.
```
# scalingìœ¼ë¡œ dataframeì—ì„œ ndarrayë¡œ ë³€í™˜ëœ ê°’ì„ ë‹¤ì‹œ dataframeìœ¼ë¡œ ë³€í™˜
test_df = pd.DataFrame(test_df, columns=columns)

# test_dfë¥¼ ì˜ˆì¸¡í•œ í›„ test_dfì˜ TARGET ì»¬ëŸ¼ì„ ë§Œë“  í›„ ê°’ì„ ì €ì¥
# ì´í›„ test_dfë¥¼ X, yë¡œ ë¶„ë¦¬
predict_santander_pred_xgb = best_lgb_model.predict(test_df)
test_df['TARGET'] = predict_santander_pred_xgb
test_y = test_df['TARGET']
test_X = test_df.drop(['TARGET'], axis=1)

# test_dfë¥¼ inverse_transform()ì„ ì´ìš©í•´ scaling ì „ìœ¼ë¡œ ë˜ëŒë¦°ë‹¤.
test_df_original = sc.inverse_transform(test_X)
test_df_original = pd.DataFrame(test_df_original, columns=columns)
test_df_original['TARGET'] = test_y.values

# test_df_originalì—ì„œ var15ì˜ ê°’ì´ 23ë³´ë‹¤ ì‘ìœ¼ë©´ 0ìœ¼ë¡œ ë³€ê²½
test_df_original.loc[test_df_original['var15'] < 23, 'TARGET'] = 0

# submission_dfì— test_df_originalì˜ TARGETì„ ì €ì¥
santander_submission_df['TARGET'] = test_df_original['TARGET']
santander_submission_df.to_csv('santander_submission_lgbm.csv', index=False)
santander_submission_df
```
kaggleì— ì œì¶œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì ìˆ˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì˜ˆìƒí–ˆë“¯ì´ XGBoostê°€ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤.
![image](https://github.com/user-attachments/assets/749092ee-2b0b-43b0-b7b2-65bc7c573650)

   #### CatBoost
ë‹¤ìŒìœ¼ë¡œ ì§„í–‰í•  ëª¨ë¸ì€ CatBoostì´ë‹¤. CatBoostëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ê°€ ë§ì€ ë°ì´í„°ì…‹ì—ì„œ íƒì›”í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤. í•˜ì§€ë§Œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ë°ì´í„°ì—ì„œë„ ë†’ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë©°, ê³¼ì í•© ë°©ì§€, ë³‘ë ¬ ì²˜ë¦¬ ë° íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ìœ¼ë¡œ í•™ìŠµê³¼ ì˜ˆì¸¡ì´ ë¹ ë¥´ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤. ë˜í•œ, ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì´ ìˆì–´ í¸ë¦¬í•˜ë‹¤. í•˜ì§€ë§Œ í•„ìëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ optunaë¥¼ í†µí•´ í•  ì˜ˆì •ì´ë‹¤.
```
from catboost import CatBoostClassifier

def objective(trial):
    param = {
        'loss_function': 'Logloss',
        'eval_metric': 'F1',
        'iterations': trial.suggest_int('iterations', 100, 1000),
        'depth': trial.suggest_int('depth', 4, 10),  # max_depthì— í•´ë‹¹
        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True),
        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),
        'random_strength': trial.suggest_float('random_strength', 0.5, 2.0),
        'border_count': trial.suggest_int('border_count', 32, 255),  # colsample_bytreeì— í•´ë‹¹í•˜ëŠ” ì—­í• 
        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),
        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 50.0)
    }

    cat_model = CatBoostClassifier(**param, random_state=42, verbose=0)
    cat_model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True, early_stopping_rounds=50)

    y_val_pred = cat_model.predict(X_val)
    f1 = f1_score(y_val, y_val_pred)
    return f1

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)

best_params = study.best_params
print("Best params: ", best_params)

best_cat_model = CatBoostClassifier(**best_params, random_state=42, verbose=0)
best_cat_model.fit(X_train, y_train)

y_val_pred = best_cat_model.predict(X_val)


y_train_pred = best_cat_model.predict(X_train)
y_train_pred_proba = best_cat_model.predict_proba(X_train)[:, 1]

y_test_pred = best_cat_model.predict(X_val)
y_test_pred_proba = best_cat_model.predict_proba(X_val)[:, 1]


print("Train Data Evaluation:")
get_clf_eval(y_train, y_train_pred, y_train_pred_proba)
print("\nValidation Data Evaluation:")
get_clf_eval(y_val, y_test_pred, y_test_pred_proba)
```
```
Train Data Evaluation:
ì˜¤ì°¨ í–‰ë ¬
[[6439  994]
 [ 620 1615]]
ì •í™•ë„: 0.8331, ì •ë°€ë„: 0.6190, ì¬í˜„ìœ¨: 0.7226,    F1: 0.6668, AUC:0.8838

Validation Data Evaluation:
ì˜¤ì°¨ í–‰ë ¬
[[1578  285]
 [ 192  362]]
ì •í™•ë„: 0.8026, ì •ë°€ë„: 0.5595, ì¬í˜„ìœ¨: 0.6534,    F1: 0.6028, AUC:0.8411
```
ìœ„ì™€ ê°™ì€ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. XGBoost ë³´ë‹¤ëŠ” ê³¼ì í•©ì´ ë§ì´ í•´ì†Œëœ ê²ƒìœ¼ë¡œ ë³´ì´ì§€ë§Œ ì „ì²´ì ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë‚®ë‹¤. íŠ¹íˆ, ì •ë°€ë„ê°€ ë‚®ì€ë°, ì´ëŠ” ì–‘ì„±ìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²ƒë“¤ ì¤‘ ì‹¤ì œë¡œ ë§ì¶˜ ë¹„ìœ¨ì´ ë‚®ë‹¤. ê·¸ëŸ¼ì—ë„ ì´ë²ˆ ë°ì´í„°ì˜ í‰ê°€ ì§€í‘œì¸ AUCëŠ” ì–‘í˜¸í•œ ì ìˆ˜ë¥¼ ë³´ì—¬ì£¼ê³  ìˆë‹¤. kaggleì— ì œì¶œí•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ì ìˆ˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
![image](https://github.com/user-attachments/assets/f5b68839-dba9-420a-9d4c-1ad40252be86)

   #### Ensemble
ë§ˆì§€ë§‰ìœ¼ë¡œ ì§„í–‰í•  ëª¨ë¸ì€ Ensemble ì´ë‹¤. ì—¬ëŸ¬ ê°œì˜ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ í•˜ë‚˜ì˜ ëª¨ë¸ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì–»ëŠ” ê¸°ë²•ì´ë‹¤. ì´ëŸ° ë°©ë²•ì„ ì‚¬ìš©í•˜ë©´ ê°œë³„ ëª¨ë¸ì´ ê°€ì§€ëŠ” ì•½ì ì„ ë³´ì™„í•˜ê³  ì˜ˆì¸¡ì˜ ì•ˆì •ì„±ì„ ë†’ì´ëŠ” ë° ìœ ë¦¬í•˜ë‹¤.

ì„±ëŠ¥ í–¥ìƒ: ê°œë³„ ëª¨ë¸ë³´ë‹¤ ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì•ˆì •ì„±: í•˜ë‚˜ì˜ ëª¨ë¸ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì˜¤ë¥˜ë‚˜ í¸í–¥ì„ ì¤„ì…ë‹ˆë‹¤.
ìœ ì—°ì„±: ì„œë¡œ ë‹¤ë¥¸ ìœ í˜•ì˜ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ë” ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ìœ„ì™€ ê°™ì€ ì¥ì ì´ ìˆìœ¼ë©°, Bagging (ë°°ê¹…), Boosting (ë¶€ìŠ¤íŒ…), Stacking (ìŠ¤íƒœí‚¹), Voting (ë³´íŒ…)ì´ ìˆë‹¤. ì´ë²ˆì—ëŠ” ë³´íŒ… ê·¸ ì¤‘ì—ì„œë„ ì†Œí”„íŠ¸ ë³´íŒ…ì„ ì‚¬ìš©í•˜ë ¤ê³  í•œë‹¤. ë³´íŒ…ì€ ì—¬ëŸ¬ ê°œì˜ ëª¨ë¸ì„ í•™ìŠµí•œ í›„, ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì„ íˆ¬í‘œ ë°©ì‹ìœ¼ë¡œ ê²°í•©í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ì„ ë„ì¶œí•˜ëŠ” ë°©ì‹ì´ë‹¤. ë‹¤ìˆ˜ê²° ë˜ëŠ” ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë°©ì‹ìœ¼ë¡œ ìµœì¢… ê²°ê³¼ë¥¼ ì‚°ì¶œí•  ìˆ˜ ìˆë‹¤.

í•˜ë“œ ë³´íŒ…ì€ ê° ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í´ë˜ìŠ¤(ë¼ë²¨) ì¤‘ ë‹¤ìˆ˜ê²°ë¡œ ìµœì¢… í´ë˜ìŠ¤ë¥¼ ì„ íƒí•˜ë©°, ì†Œí”„íŠ¸ ë³´íŒ…ì€ ëª¨ë¸ë“¤ì´ ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ í™•ë¥  ê°’ì„ í‰ê·  ë‚´ì„œ ìµœì¢… í´ë˜ìŠ¤ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒìœ¼ë¡œ í™•ë¥  ê°’ì´ ë°˜ì˜ë˜ë¯€ë¡œ ë” ì •í™•í•œ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•  ìˆ˜ ìˆë‹¤.
```
from sklearn.ensemble import VotingClassifier, AdaBoostClassifier, RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

# ëª¨ë¸ ì •ì˜
decision_tree_clf = DecisionTreeClassifier(random_state=42)
svm_clf = SVC(probability=True, random_state=42)
log_reg_clf = LogisticRegression(random_state=42)
adaboost_clf = AdaBoostClassifier(random_state=42)
lgbm_clf = LGBMClassifier(random_state=42, verbose=-1)
catboost_clf = CatBoostClassifier(random_state=42, verbose=0)
rf_clf = RandomForestClassifier(random_state=42)

# VotingClassifierë¥¼ ì‚¬ìš©í•œ ì†Œí”„íŠ¸ ë³´íŒ… ëª¨ë¸ ì •ì˜ (voting='soft')
voting_clf = VotingClassifier(
    estimators=[
        ('decision_tree', decision_tree_clf), 
        ('svm', svm_clf), 
        ('log_reg', log_reg_clf),
        ('adaboost', adaboost_clf), 
        ('lgbm', lgbm_clf), 
        ('catboost', catboost_clf), 
        ('rf', rf_clf)
    ], 
    voting='soft'  # ì†Œí”„íŠ¸ ë³´íŒ… ì‚¬ìš©
)

voting_clf.fit(X_train, y_train)
y_pred = voting_clf.predict(X_val)

accuracy = accuracy_score(y_val, y_pred)
print(f"Soft Voting Classifier Accuracy: {accuracy:.4f}")

# ê°œë³„ ëª¨ë¸ì˜ ì„±ëŠ¥ í™•ì¸ (ê° ëª¨ë¸ì˜ ì„±ëŠ¥ë„ ì¶œë ¥)
for clf in (decision_tree_clf, svm_clf, log_reg_clf, adaboost_clf, lgbm_clf, catboost_clf, rf_clf, voting_clf):
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_val)
    print(f"{clf.__class__.__name__} Accuracy: {accuracy_score(y_val, y_pred):.4f}")
```
```
Soft Voting Classifier Accuracy: 0.8481
LGBMClassifier Accuracy: 0.8415
CatBoostClassifier Accuracy: 0.8422
XGBClassifier Accuracy: 0.8394
RandomForestClassifier Accuracy: 0.8299
SVC Accuracy: 0.7952
```
ê°ê° ëª¨ë¸ì— ëŒ€í•´ ìœ„ì˜ ê²°ê³¼ì²˜ëŸ¼ ì¶œë ¥ì´ ëœë‹¤. ë¹„ìŠ·í•œ ì ìˆ˜ëŒ€ë¥¼ ë³´ì—¬ì£¼ì§€ë§Œ VotingClassifierê°€ ê°œë³„ ëª¨ë¸ë“¤ë³´ë‹¤ ì•½ê°„ ë” ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆìœ¼ë¯€ë¡œ ì˜ ì‘ë™í•˜ê³  ìˆë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. 
```
y_train_pred = voting_clf.predict(X_train)
y_train_pred_proba = voting_clf.predict_proba(X_train)[:, 1]

y_test_pred = voting_clf.predict(X_val)
y_test_pred_proba = voting_clf.predict_proba(X_val)[:, 1]

print("Train Data Evaluation:")
get_clf_eval(y_train, y_train_pred, y_train_pred_proba)

print("\nValidation Data Evaluation:")
get_clf_eval(y_val, y_test_pred, y_test_pred_proba)
```
```
Train Data Evaluation:
ì˜¤ì°¨ í–‰ë ¬
[[8464  282]
 [ 693 1962]]
ì •í™•ë„: 0.9145, ì •ë°€ë„: 0.8743, ì¬í˜„ìœ¨: 0.7390,    F1: 0.8010, AUC:0.9758

Validation Data Evaluation:
ì˜¤ì°¨ í–‰ë ¬
[[2069  148]
 [ 285  349]]
ì •í™•ë„: 0.8481, ì •ë°€ë„: 0.7022, ì¬í˜„ìœ¨: 0.5505,    F1: 0.6172, AUC:0.8619
```

ê²°ê³¼ì— ëŒ€í•œ í‰ê°€ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ì´ì „ì— í•™ìŠµí–ˆë˜ ëª¨ë¸ë“¤ì— ë¹„í•´ ê³¼ì í•©ì´ ë‹¤ì‹œ ì‹¬í•´ì¡Œë‹¤. kaggleì— ì œì¶œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì ìˆ˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. Ensembleì€ ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëƒì— ë”°ë¼ ì„±ëŠ¥ì´ ë‹¬ë¼ì§„ë‹¤. íŠ¹íˆ Votingì€ ì‚¬ìš©í•˜ëŠ” ê°œë³„ ëª¨ë¸ì˜ íŠ¹ì„±ì— ë”°ë¼ ì„±ëŠ¥ì´ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ëª¨ë¸ ì„ íƒì´ ì¤‘ìš”í•˜ë‹¤. ê·¸ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. 

ì„±ëŠ¥ í–¥ìƒì˜ í•µì‹¬ì€ ëª¨ë¸ì˜ ë‹¤ì–‘ì„±ìœ¼ë¡œ Voting ì•™ìƒë¸”ì€ ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê°€ì§„ ëª¨ë¸ì„ ê²°í•©í•  ë•Œ ë” íš¨ê³¼ì ì´ê¸° ë•Œë¬¸ì´ë‹¤. ë™ì¼í•œ íŠ¹ì„±ì„ ê°€ì§„ ëª¨ë¸ë“¤ì„ ê²°í•©í•˜ë©´ ì„±ëŠ¥ ê°œì„  íš¨ê³¼ê°€ ì œí•œì ì¼ ìˆ˜ ìˆì–´ ëª¨ë¸ ì„ íƒì´ ì¤‘ìš”í•˜ë‹¤. ë”°ë¼ì„œ ì§€ê¸ˆê³¼ ê°™ì€ ì ìˆ˜ëŠ” ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëƒì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤.
![image](https://github.com/user-attachments/assets/9327ae2d-fb31-4199-99e9-2df484de82a3)

---

ì¶”ê°€ì ìœ¼ë¡œ noise ê°’ì˜ TARGET ê°’ì„ ì˜ˆì¸¡í•˜ì§€ ì•Šê³  ì œê±°í•œ ë‹¤ìŒ LightGBMìœ¼ë¡œ ì˜ˆì¸¡í–ˆì„ ë•Œê°€ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤¬ë‹¤. ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
```
Train Data Evaluation:
ì˜¤ì°¨ í–‰ë ¬
[[5830 1506]
 [ 519 1692]]
ì •í™•ë„: 0.7879, ì •ë°€ë„: 0.5291, ì¬í˜„ìœ¨: 0.7653,    F1: 0.6256, AUC:0.8581

Validation Data Evaluation:
ì˜¤ì°¨ í–‰ë ¬
[[1482  362]
 [ 150  393]]
ì •í™•ë„: 0.7855, ì •ë°€ë„: 0.5205, ì¬í˜„ìœ¨: 0.7238,    F1: 0.6055, AUC:0.8385
```
train dataì˜ ê²°ê³¼ê°€ ì¬í˜„ìœ¨ì´ ë†’ì€ë° ì •ë°€ë„ê°€ ë‚®ë‹¤. ì¦‰, ì–‘ì„± í´ë˜ìŠ¤ë¥¼ ì˜ ì¡ì•„ë‚´ì§€ë§Œ, ë§ì€ ì˜ëª»ëœ ê¸ì • (False Positive)ë„ ì˜ˆì¸¡í•˜ê³  ìˆë‹¤. ê·¸ë˜ë„ ì´ì „ì— ë¹„í•´ ê³¼ì í•©ì´ ë§ì´ í•´ì†Œëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì¬í˜„ìœ¨, ì •ë°€ë„ì— ëŒ€í•œ í•´ê²° ë°©ë²•ìœ¼ë¡œ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ê· í˜• ì¡°ì •, ëª¨ë¸ ë³µì¡ë„ ì¤„ì´ê¸°, ëª¨ë¸ ì•™ìƒë¸”ì´ ìˆë‹¤.

ê²°ê³¼ë¥¼ kaggleì— ì œì¶œí–ˆì„ ë•Œ private, public ëª¨ë‘ ì´ì „ê³¼ ë§ì´ ì¢‹ì•„ì§„ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
![image](https://github.com/user-attachments/assets/b524df6f-6b21-4745-8293-3dc522473c30)

ë² ìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
```
Best params:  {'num_leaves': 44, 'min_child_samples': 30, 'min_child_weight': 7.026190601165056, 'max_depth': 3, 'subsample': 0.6587318096159958, 'colsample_bytree': 0.6087483644642271, 'learning_rate': 0.01961668163863785, 'scale_pos_weight': 2.762646582387838, 'reg_alpha': 2.1002708478959153, 'reg_lambda': 18.205433395806338, 'n_estimators': 586}
```

### ê²°ë¡ 
ì´ë²ˆ Santander Customer Satisfaction í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ë°ì´í„° ë¶„ì„ ë° ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•ì„ í•™ìŠµí•˜ê³  ì ìš©í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ëŒ€ê·œëª¨ì˜ ìµëª…í™”ëœ íŠ¹ì„±ë“¤ì„ ë‹¤ë£¨ë©°, ì´ ë°ì´í„°ì…‹ì˜ íŠ¹ì§•ì„ íŒŒì•…í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ë° ìƒë‹¹í•œ ë…¸ë ¥ì„ ê¸°ìš¸ì˜€ìŠµë‹ˆë‹¤. Feature Engineeringì„ í†µí•´ ë°ì´í„°ë¥¼ ì •ì œí•˜ê³ , ì´ìƒì¹˜ ë° ë…¸ì´ì¦ˆë¥¼ ì²˜ë¦¬í•˜ëŠ” ê³¼ì •ì—ì„œ ì—¬ëŸ¬ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì„ ì‹œë„í•˜ì˜€ìŠµë‹ˆë‹¤.

ëª¨ë¸ í•™ìŠµì—ì„œëŠ” votingì„ ì‚¬ìš©í•˜ê¸°ë„ í–ˆì§€ë§Œ XGBoost, LightGBM, CatBoostì™€ ê°™ì€ ë¶€ìŠ¤íŒ… ê¸°ë²•ì„ ì‚¬ìš©í•´ ë†’ì€ ì„±ëŠ¥ì„ ëª©í‘œë¡œ í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ì´ í”„ë¡œì íŠ¸ì—ì„œ ì¤‘ìš”í•œ í‰ê°€ì§€í‘œëŠ” AUC (ROC ê³¡ì„  ì•„ë˜ ë©´ì )ì˜€ìœ¼ë©°, ì´ëŠ” ê³ ê° ë¶ˆë§Œì¡± ì˜ˆì¸¡ì´ë¼ëŠ” ë¬¸ì œ íŠ¹ì„±ì— ë§ì¶”ì–´ ì¬í˜„ìœ¨ê³¼ ì •ë°€ë„ë¥¼ ê· í˜• ìˆê²Œ ê³ ë ¤í•œ ëª¨ë¸ í‰ê°€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•´ì£¼ì—ˆìŠµë‹ˆë‹¤.

#### í•œê³„ì 
í”„ë¡œì íŠ¸ ì§„í–‰ ì¤‘ ê°€ì¥ ì•„ì‰¬ì› ë˜ ì ì€ ë°ì´í„°ì˜ ë¹„ëŒ€ì¹­ì„±(imbalance)ì´ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ì—ì„œ ë¶ˆë§Œì¡± ê³ ê°ì˜ ë¹„ìœ¨ì´ ë§¤ìš° ë‚®ì•˜ê¸° ë•Œë¬¸ì—, ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì–¸ë”ìƒ˜í”Œë§ì„ ì‚¬ìš©í–ˆì§€ë§Œ, ë°ì´í„° ì†ì‹¤ë¡œ ì¸í•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì™„ë²½íˆ ê°œì„ ë˜ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤. ë˜í•œ, ìµëª…í™”ëœ íŠ¹ì„± ë•Œë¬¸ì— ë³€ìˆ˜ë“¤ì˜ ì˜ë¯¸ë¥¼ ëª…í™•íˆ ì´í•´í•˜ì§€ ëª»í•˜ê³ , ê·¸ë¡œ ì¸í•´ íš¨ê³¼ì ì¸ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ì˜ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì´ ì–´ë ¤ì› ìŠµë‹ˆë‹¤.

#### ë°°ìš´ ì 
ì´ë²ˆ í”„ë¡œì íŠ¸ëŠ” ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ê³µí•™ì˜ ì¤‘ìš”ì„±ì„ ë‹¤ì‹œ í•œë²ˆ ê¹¨ë‹«ê²Œ í•´ì£¼ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ì´ìƒì¹˜ íƒì§€, ë…¸ì´ì¦ˆ ì²˜ë¦¬ëŠ” ëª¨ë¸ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ëŠ” ì¤‘ìš”í•œ ë‹¨ê³„ì„ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë‹¤ì–‘í•œ ì•™ìƒë¸” ê¸°ë²•ê³¼ ê·¸ë“¤ì˜ ì¥ë‹¨ì ì„ ë¹„êµí•˜ëŠ” ê²½í—˜ì„ í†µí•´ Voting, Boostingì˜ ì°¨ì´ë¥¼ ì²´ê°í•˜ë©° Ensembleì— ëŒ€í•´ ë” ê¹Šê²Œ ê³µë¶€í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

ë¹„ë¡ ëª©í‘œí–ˆë˜ ìµœê³  ì„±ëŠ¥ì—ëŠ” ë¯¸ì¹˜ì§€ ëª»í–ˆì§€ë§Œ, ì—¬ëŸ¬ ì‹œí–‰ì°©ì˜¤ë¥¼ ê±°ì¹˜ë©° ì„±ì¥í•  ìˆ˜ ìˆì—ˆë˜ ì˜ë¯¸ ìˆëŠ” í”„ë¡œì íŠ¸ì˜€ìŠµë‹ˆë‹¤.

